# from transformers import BlipProcessor, BlipForConditionalGeneration
# from PIL import Image
# import requests
# import json
# from dotenv import load_dotenv
# import os
# load_dotenv()

# # Load the processor and model
# processor = BlipProcessor.from_pretrained('Salesforce/blip-image-captioning-base', use_fast = True)
# model = BlipForConditionalGeneration.from_pretrained('Salesforce/blip-image-captioning-base')
# # Load an image from a URL
# # url = "https://media.geeksforgeeks.org/wp-content/uploads/20240809103146/istockphoto-1429989403-2048x2048.jpg"
# # url = "https://images.pexels.com/photos/32882809/pexels-photo-32882809.jpeg"
# # url = "https://images.pexels.com/photos/12575856/pexels-photo-12575856.jpeg"
# # url = "https://images.pexels.com/photos/31868163/pexels-photo-31868163.jpeg"
# url = "https://images.pexels.com/photos/32859502/pexels-photo-32859502.jpeg"
# image = Image.open(requests.get(url, stream=True).raw)
# # Preprocess the image
# inputs = processor(images=image, return_tensors="pt")

# # Generate a caption
# output = model.generate(**inputs)

# # Decode the output
# caption = processor.decode(output[0], skip_special_tokens=True)
# print("Generated Caption:", caption)
# # To run this code you need to install the following dependencies:
# # pip install google-genai

# import base64
# import os
# from google import genai
# from google.genai import types

# PROMPT_TEMPLATE = """
# You are an expert Instagram content creator. The generated captions should look like it were generated by a human. Don't use repetative AI words or phrases.
# Your task is to generate creative and discoverable captions for an image described as follows:
# "{description}"

# Generate distinct styles of captions: 'Evocative & Broad', 'Intriguing & Question-Based', 'Short & Punchy with Keywords', 'A touch of poetic','Focus on the feeling','Witty', 'Inspirational', and 'Minimalist'.
# For each style, provide 2 unique caption options.

# Respond with ONLY a valid JSON object and nothing else. Do not include markdown formatting like ```json or any other explanatory text.
# The JSON object must follow this structure:
# [
#   {{
#     "style": "Witty",
#     "captions": [
#       "Caption 1 text with relevant emojis and hashtags.",
#       "Caption 2 text with relevant emojis and hashtags."
#     ]
#   }},
#   {{
#     "style": "Inspirational",
#     "captions": [
#       "Caption 1 text with relevant emojis and hashtags.",
#       "Caption 2 text with relevant emojis and hashtags."
#     ]
#   }},
#   {{
#     "style": "Minimalist",
#     "captions": [
#       "Caption 1 text with relevant emojis and hashtags.",
#       "Caption 2 text with relevant emojis and hashtags."
#     ]
#   }}
# ]
# """


# def generate():
#     client = genai.Client(
#         api_key=os.getenv('GOOGLE_API_KEY'),
#     )

#     model = "gemma-3n-e2b-it"
#     contents = [
#         types.Content(
#             role="user",
#             parts=[
#                 types.Part.from_text(text=f"{PROMPT_TEMPLATE}. The caption is {caption} "),
#             ],
#         ),
#     ]
#     generate_content_config = types.GenerateContentConfig(
#     )

#     full_response = ""
#     for chunk in client.models.generate_content_stream(
#         model=model,
#         contents=contents,
#         config=generate_content_config,
#     ):
#         if chunk.text:
#             full_response += chunk.text

#     # Clean and parse once
#     cleaned_text = full_response.strip().replace("```json", "").replace("```", "")
#     try:
#         parsed_captions = json.loads(cleaned_text)
#         print(json.dumps(parsed_captions, indent=2))
#     except json.JSONDecodeError as e:
#         print("‚ùå Failed to parse JSON. Raw output:")
#         print(cleaned_text)
#         print(f"\nError: {e}")

#     # for chunk in client.models.generate_content_stream(
#     #     model=model,
#     #     contents=contents,
#     #     config=generate_content_config,
#     # ):
#     #     print(chunk.text, end="")
#     #     cleaned_text = chunk.text.strip("```json").strip("```").strip("None")
#     #     parsed_captions = json.loads(chunk.text)

#     #     print(parsed_captions)

# if __name__ == "__main__":
#     generate()




# Load an image from a URL
# url = "https://media.geeksforgeeks.org/wp-content/uploads/20240809103146/istockphoto-1429989403-2048x2048.jpg"
# url = "https://images.pexels.com/photos/32882809/pexels-photo-32882809.jpeg"
# url = "https://images.pexels.com/photos/12575856/pexels-photo-12575856.jpeg"
# url = "https://images.pexels.com/photos/31868163/pexels-photo-31868163.jpeg"
# url = "https://images.pexels.com/photos/32859502/pexels-photo-32859502.jpeg"
# url = "https://images.pexels.com/photos/31527643/pexels-photo-31527643.jpeg"

from blip_image_classification import image_classification
#     caption_json = image_classification(url)


# if __name__ == "__main__":

from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
import uvicorn
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allows all origins
    allow_credentials=True,
    allow_methods=["*"],  # Allows all methods
    allow_headers=["*"],  # Allows all headers
)

@app.get("/")
async def root():
    return {"message": "Welcome to the Instagram AI Image Caption Maker API!"}
@app.post("/upload_image/")
async def upload_image(file:UploadFile = File(...)):
    #Validate image type by content type
    if not file.content_type.startswith('image/'):
        return JSONResponse(status_code=400, content={"message": "Invalid file type. Please upload an image."})
    
    # Read image bytes
    image_bytes = await file.read()
    caption_json = image_classification(image_bytes)
    print(caption_json)
    if caption_json:
        return JSONResponse(status_code=200, content=caption_json)
    else:
        return JSONResponse(status_code=500, content={"message": "Failed to generate captions."})
    

if __name__ == "__main__":
    uvicorn.run(app, port=3000)